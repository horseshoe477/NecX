{
 "metadata": {
  "name": "NecX_Analysis-v2.3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from numpy import fft       # FT\n",
      "from scipy import fftpack   # DFT\n",
      "\n",
      "DB = '/Volumes/Data/local/download/Research/NecX/GitHub/NecX/Data/20140607/'\n",
      "#filelist = ['Rotate.csv','Tilt.csv','UTilt.csv','mouth.csv']\n",
      "filelist = ['LRotate.csv','UTilt.csv']\n",
      "#filelist = ['LRotate.csv']\n",
      "filelist = ['UTilt.csv']\n",
      "#filelist = ['mouth.csv']\n",
      "\n",
      "#classes = [s[5:-4] for s in filelist]\n",
      "classes = [s[0:-4] for s in filelist]\n",
      "\n",
      "ch = 2   # Number of channels\n",
      "\n",
      "# Parameters for segmentation\n",
      "smoothWinSize = 50\n",
      "segSmoWinSize = 80\n",
      "#\n",
      "Th = 0.04\n",
      "slideWinSize = 500\n",
      "\n",
      "# Parameters for feature extraction\n",
      "NumOfFeature = 7\n",
      "\n",
      "# For WEKA\n",
      "f = open(\"NecX.arff\", \"w\")              # Open file\n",
      "writeArffHeader(f,NumOfFeature,classes) # Write header for .arff\n",
      "\n",
      "zcList = []\n",
      "\n",
      "for i in range(len(filelist)):\n",
      "    filename  = filelist[i]\n",
      "    className = filename[:-4]   # Weka class name\n",
      "    Root = DB + filename\n",
      "    fo = open(Root)\n",
      "    lines = fo.readlines()\n",
      "    fo.close()\n",
      "    \n",
      "    # ====================================\n",
      "    # Read raw data\n",
      "    # Fill-in data array\n",
      "    rawData = [[0]*len(lines) for i in range(ch)]\n",
      "    for idx in range(len(rawData[0])):\n",
      "        tokens = lines[idx].split(',')\n",
      "        if len(tokens)==ch:\n",
      "            rawData[0][idx] = (float)(tokens[0])   # Use ch1\n",
      "            rawData[1][idx] = (float)(tokens[1])   # Use ch2\n",
      "    '''\n",
      "    rawData[0] = rawData[0][500:700]\n",
      "    rawData[1] = rawData[1][500:700]\n",
      "    '''\n",
      "    # ====================================\n",
      "    # Segmentation\n",
      "    smoData,difData,sumOfDif,dif_sumOfDif,segStart,segEnd = segmentation(rawData, smoothWinSize, segSmoWinSize, Th,slideWinSize)\n",
      "    \n",
      "    # ====================================\n",
      "    # Plotting\n",
      "    bIsDebug = True\n",
      "    myPlotting(bIsDebug, Th,segStart,segEnd)\n",
      "    print myFFT(smoData[0][0:2047],className)\n",
      "    #myFFT(rawData[1],className)\n",
      "    \n",
      "    # ====================================\n",
      "    # Feature extraction and generate .arff file\n",
      "    for isc in range(len(segStart)):\n",
      "        start = int(segStart[isc])\n",
      "        end = int(segEnd[isc])\n",
      "        features1 = smoData[0][start:end]\n",
      "        features2 = smoData[1][start:end]\n",
      "        # Zero mean\n",
      "        features1 = features1 - np.mean(features1)\n",
      "        features2 = features2 - np.mean(features2)\n",
      "        writeArffData(f,features1,features2,className)\n",
      "        \n",
      "        #--------------------\n",
      "        zero_crossing1 = np.where(np.diff(np.sign(features1)))[0]  \n",
      "        zero_crossing2 = np.where(np.diff(np.sign(features2)))[0]  \n",
      "        '''\n",
      "        nF1 = rawData[0][start:end]\n",
      "        nF2 = rawData[1][start:end]\n",
      "        nF1 = nF1 - np.mean(nF1)\n",
      "        nF2 = nF2 - np.mean(nF2)\n",
      "        zero_crossing1 = np.where(np.diff(np.sign(nF1)))[0]  \n",
      "        zero_crossing1 = np.where(np.diff(np.sign(nF2)))[0]\n",
      "        '''\n",
      "        zc = len(zero_crossing1) + len(zero_crossing2)\n",
      "        #print zc\n",
      "        zcList.append(zc)\n",
      "        \n",
      "        '''\n",
      "        #plt.close('all')\n",
      "        x = np.linspace(0, len(features1), num=len(features1))\n",
      "        f10, ax10 = plt.subplots(ch, sharex=True, sharey=True, figsize=(6, 10))\n",
      "        ax10[0].plot(x, features1)\n",
      "        ax10[1].plot(x, features2)\n",
      "        plt.title(className + ' Features')\n",
      "        '''\n",
      "    \n",
      "    print className,len(segStart),np.mean(zcList)\n",
      "    \n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.95503421]\n",
        "UTilt 19 7.57894736842\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ===================================\n",
      "# Reshape the curve using interpolation\n",
      "# ===================================\n",
      "from scipy import interpolate\n",
      "\n",
      "def myResample(data,newSize):\n",
      "    N = len(data)\n",
      "\n",
      "    x = np.linspace(0.0, N, N)\n",
      "    f = interpolate.interp1d(x,data)\n",
      "\n",
      "    # re-sampling\n",
      "    newX = np.linspace(0.0, N, newSize)\n",
      "    newData = f(newX)\n",
      "    \n",
      "    return newData"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ===================================\n",
      "# Moving average\n",
      "# ===================================\n",
      "def movingAvg(values,window):\n",
      "    weigths = np.repeat(1.0, window)/window\n",
      "    smas = np.convolve(values, weigths, 'valid')\n",
      "    return smas # as a numpy array\n",
      "\n",
      "# ===================================\n",
      "# Write arff data\n",
      "# ===================================\n",
      "def writeArffData(f,features1,features2,className):\n",
      "    maxCh1 = max(features1)\n",
      "    minCh1 = min(features1)\n",
      "    maxCh2 = max(features2)\n",
      "    minCh2 = min(features2)\n",
      "    selfCorr1 = max(np.correlate(features1, features1, 'full'))\n",
      "    selfCorr2 = max(np.correlate(features2, features2, 'full'))\n",
      "    crosCorr  = max(np.correlate(features1, features2, 'full'))\n",
      "    f.write('%d,' % int(maxCh1 - maxCh2))\n",
      "    f.write('%d,' % int(minCh1 - minCh2))\n",
      "    f.write('%d,' % int(maxCh1 - minCh1))\n",
      "    f.write('%d,' % int(maxCh2 - minCh2))\n",
      "    f.write('%d,' % int(selfCorr1))\n",
      "    f.write('%d,' % int(selfCorr2))\n",
      "    f.write('%d,' % int(crosCorr))\n",
      "    f.write('%s\\n' % className)\n",
      "\n",
      "# ===================================\n",
      "# Write arff header\n",
      "# ===================================\n",
      "def writeArffHeader(f, NumOfFeature, classes):\n",
      "    # Write the name of dataset\n",
      "    f.write('@RELATION NecX\\n\\n')\n",
      "    # Features and type\n",
      "    for i in range(NumOfFeature):\n",
      "        f.write('@ATTRIBUTE f%d NUMERIC\\n' % i)\n",
      "    # Classes\n",
      "    f.write('@ATTRIBUTE class {')\n",
      "    for i in range(len(classes)):\n",
      "        f.write(classes[i])\n",
      "        if i != len(classes)-1:\n",
      "            f.write(',')\n",
      "    f.write('}\\n\\n')\n",
      "    # Data\n",
      "    f.write('@DATA\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def segmentation(rawData, smoothWinSize, segSmoWinSize, Th,slideWinSize):\n",
      "    \n",
      "    minWin = slideWinSize*0.3\n",
      "    centerShift = smoothWinSize*1.1\n",
      "    extendWinSize = 80\n",
      "    \n",
      "    # ====================================\n",
      "    # Moving average & 1st derivative of respective channels\n",
      "    # ====================================\n",
      "    smoData = [None]*2\n",
      "    difData = [None]*2\n",
      "    for i in range(ch):\n",
      "        smoData[i] = movingAvg(rawData[i], smoothWinSize)  # Moving average\n",
      "        difData[i] = np.absolute(np.diff(smoData[i]))      # Absolute of the 1st derivative\n",
      "    \n",
      "    # ====================================\n",
      "    # Sum of absolute of the 1st Derivative\n",
      "    # ====================================\n",
      "    amplify = 2\n",
      "    sumOfDif = movingAvg([x+y for x,y in zip(difData[0], difData[1])], segSmoWinSize) * amplify\n",
      "    dif_sumOfDif = movingAvg(np.diff(sumOfDif), segSmoWinSize)\n",
      "\n",
      "    # ====================================\n",
      "    # Segmentation\n",
      "    # ====================================\n",
      "    segStart = []\n",
      "    segEnd = []\n",
      "    i = 0\n",
      "    while i < len(dif_sumOfDif)-1:\n",
      "        i = i + 1\n",
      "        hit = False\n",
      "        if dif_sumOfDif[i-1]<Th and dif_sumOfDif[i]>=Th:\n",
      "            start = i\n",
      "\n",
      "            while i < start+slideWinSize and i < len(dif_sumOfDif)-1:\n",
      "                i = i + 1\n",
      "                if dif_sumOfDif[i-1] < -Th and dif_sumOfDif[i] >= -Th:\n",
      "                    end = i\n",
      "                    if end-start > minWin:   # Gesture length is not too short (half window size)\n",
      "                        hit = True\n",
      "                        break\n",
      "\n",
      "            if hit == True:\n",
      "                segStart.append(start+centerShift)\n",
      "                segEnd.append(end+centerShift+extendWinSize)\n",
      "                hit = False\n",
      "                i = end+1\n",
      "            #else:\n",
      "            #    i = start + minWin   # reset the searching point for the next gesture\n",
      "    \n",
      "    return smoData,difData,sumOfDif,dif_sumOfDif,segStart,segEnd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ===================================\n",
      "# Plotting\n",
      "# ===================================\n",
      "def myPlotting(bIsDebug, Th,segStart,segEnd):\n",
      "    \n",
      "    plt.close('all')\n",
      "    \n",
      "    # Smoothing\n",
      "    x = np.linspace(0, len(smoData[0]), num=len(smoData[0]))\n",
      "    f2, ax2 = plt.subplots(ch, sharex=True, sharey=True, figsize=(10, 6))\n",
      "    for i in range(ch):\n",
      "        ax2[i].plot(x, smoData[i])\n",
      "    plt.title('Smoothed')\n",
      "\n",
      "    if bIsDebug:\n",
      "        # Raw data\n",
      "        x = np.linspace(0, len(rawData[0]), num=len(rawData[0]))\n",
      "        f1, ax1 = plt.subplots(ch, sharex=True, sharey=False, figsize=(10, 6))\n",
      "        for i in range(ch):\n",
      "            ax1[i].plot(x, rawData[i])\n",
      "            ax1[i].set_ylabel('ch'+str(i))\n",
      "        plt.title('Raw')\n",
      "    \n",
      "        # Absolute of the 1st derivative\n",
      "        x = np.linspace(0, len(difData[0]), num=len(difData[0]))\n",
      "        f3, ax3 = plt.subplots(ch, sharex=True, sharey=True, figsize=(10, 6))\n",
      "        for i in range(ch):\n",
      "            ax3[i].plot(x, difData[i])\n",
      "            ax3[i].set_ylabel('ch'+str(i))\n",
      "        plt.title('Abs of 1st Derivative')\n",
      "        \n",
      "        # Sum of the absolute of the 1st derivative\n",
      "        f4, ax4 = plt.subplots(ch, sharex=True, sharey=False, figsize=(10, 6))\n",
      "        #\n",
      "        x = np.linspace(0, len(sumOfDif), num=len(sumOfDif))\n",
      "        ax4[0].plot(x, sumOfDif)\n",
      "        ax4[0].set_ylabel('Sum of Diff')\n",
      "        #\n",
      "        x = np.linspace(0, len(dif_sumOfDif), num=len(dif_sumOfDif))\n",
      "        ax4[1].plot(x, dif_sumOfDif)\n",
      "        ax4[1].set_ylabel('Diff of Sum of Diff')\n",
      "        #\n",
      "        ax4[1].axhline(y=Th, linewidth=2, color='r')\n",
      "        ax4[1].axhline(y=-Th, linewidth=2, color='r')\n",
      "        if len(segStart) > 0:\n",
      "            for i in range(len(segStart)):\n",
      "                ax4[0].axvspan(segStart[i], segEnd[i], facecolor='r', alpha=0.25)\n",
      "\n",
      "    # Plot the segmentation\n",
      "    for i in range(len(segStart)):\n",
      "        ax2[0].axvspan(segStart[i], segEnd[i], facecolor='g', alpha=0.25)\n",
      "        ax2[1].axvspan(segStart[i], segEnd[i], facecolor='g', alpha=0.25)\n",
      "\n",
      "        #print segEnd[i] - segStart[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ===================================\n",
      "# FFT\n",
      "# ===================================\n",
      "def myFFT(val, title):\n",
      "    \n",
      "    # -------------------------------\n",
      "    # Set the FFT size\n",
      "    start = 0\n",
      "    end = max(256, len(val)-1)  # In case some data has less than 256 elements\n",
      "    val = val[start:end]\n",
      "\n",
      "    # -------------------------------\n",
      "    # FFT\n",
      "    N = end - start\n",
      "    T = 4.0 / 1000.0     # Sample at 125 Hz\n",
      "    xf = fftpack.fftfreq(N,T)\n",
      "    yf = fftpack.fft(val)\n",
      "\n",
      "    # Only reserve half of the spectrum\n",
      "    psIdx = np.where(xf>0)\n",
      "    spectrum = xf[psIdx]\n",
      "    power = np.abs(yf[psIdx])**2   # Power spectrum\n",
      "\n",
      "    f, ax = plt.subplots(3, sharex=False, sharey=False, figsize=(10, 8))\n",
      "    x = np.linspace(0, len(val), len(val))\n",
      "    ax[0].plot(x, val)\n",
      "    ax[0].set_xlabel('Samples')\n",
      "    ax[0].set_ylabel('Magnitude')\n",
      "    #ax[0].set_xlim([0, end-start])\n",
      "    #ax[0].set_ylim([0, 900])\n",
      "    ax[0].grid(True)\n",
      "    #\n",
      "    ax[1].plot(spectrum, power)\n",
      "    ax[1].set_xlabel('Frequency[Hz]')\n",
      "    ax[1].set_ylabel('Power Density Spectrum')\n",
      "    ax[1].set_xlim([0, 1.0/(2.0*T)])\n",
      "    #ax[1].set_ylim([0, 1e+7 + 35e+6])\n",
      "    ax[1].grid(True)\n",
      "    #\n",
      "    TFR = ax[2].specgram(val, NFFT=256, Fs=1/T)\n",
      "    TFRdata = TFR[0]\n",
      "    freq = TFR[1]\n",
      "    time = TFR[2]\n",
      "    ax[2].set_xlabel('Time[s]')\n",
      "    ax[2].set_ylabel('Frequency[Hz]')\n",
      "    ax[2].set_xlim([0, max(time)])\n",
      "    ax[2].set_ylim([0, max(freq)])\n",
      "\n",
      "    plt.suptitle(filename)\n",
      "    plt.subplots_adjust(hspace=.35)\n",
      "    \n",
      "    return spectrum[np.where(power==max(power))[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ===================================\n",
      "# Write file\n",
      "# ===================================\n",
      "f = open(\"NecX.arff\", \"w\")\n",
      "f.write(\"hello world in the new file\\n\")\n",
      "f.write(\"and another line\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = 'NecX_myGesture.csv'\n",
      "print s[5:-4]\n",
      "\n",
      "a = [0,1,2,3,4,5]\n",
      "print a[1:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "myGesture\n",
        "[1, 2, 3]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [1,2,3,4,5]\n",
      "\n",
      "a.append(60)\n",
      "print a\n",
      "\n",
      "a.pop(0)\n",
      "a.pop(0)\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 2, 3, 4, 5, 60]\n",
        "[3, 4, 5, 60]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [-5,-3,2,2,0,-5,-2,-1]\n",
      "\n",
      "sign = np.sign(a)\n",
      "diff = np.diff(sign)\n",
      "zc = np.where(diff)\n",
      "\n",
      "print sign\n",
      "print diff\n",
      "print zc\n",
      "\n",
      "#zc = np.where(np.diff(np.sign(a)))[0] \n",
      "#print len(zc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-1 -1  1  1  0 -1 -1 -1]\n",
        "[ 0  2  0 -1 -1  0  0]\n",
        "(array([1, 3, 4]),)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm, datasets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "import pylab as pl\n",
      "\n",
      "# import some data to play with\n",
      "iris = datasets.load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "\n",
      "# Split the data into a training set and a test set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
      "\n",
      "# Run classifier\n",
      "classifier = svm.SVC(kernel='linear')\n",
      "y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
      "\n",
      "# Compute confusion matrix\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "\n",
      "print(cm)\n",
      "\n",
      "# Show confusion matrix in a separate window\n",
      "pl.matshow(cm)\n",
      "pl.title('Confusion matrix')\n",
      "pl.colorbar()\n",
      "pl.ylabel('True label')\n",
      "pl.xlabel('Predicted label')\n",
      "pl.show()  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named sklearn",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-9a89619d3430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named sklearn"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}